{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qvvBRLfDjAx",
    "outputId": "464193ea-f866-44cc-b8ed-01c5aecd357c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: keybert in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.0.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.7/dist-packages (from keybert) (2.2.0)\n",
      "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.7/dist-packages (from keybert) (12.4.4)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (4.2.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (2.6.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.19.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.64.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.12.0+cu113)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.2.5)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.1.96)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.11.0+cu113)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.7.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (4.11.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "6p34-sTmD0nN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import csv\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ho1GSxvVD-Gj",
    "outputId": "231c8ba6-d6e9-44fa-9269-e47af9ddbd18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 122433: unexpected end of data\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/content/topicModelingData.csv', error_bad_lines=False, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVtpLe7yEEvo",
    "outputId": "5cf841e3-77a4-4922-83b0-e1d6506e8755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('vaccine', 0.4391), ('vaccinated', 0.4285), ('vaccines', 0.4239), ('vaccinations', 0.4228), ('vaccination', 0.4129)]\n",
      "[('covidvaccination', 0.5707), ('covid', 0.5065), ('covidfl', 0.4961), ('covid19tracking', 0.4924), ('vaccinehesitancy', 0.4855)]\n",
      "[('covidvaccination', 0.4614), ('precautions', 0.4281), ('vaccinationrate', 0.4063), ('vaccineequity', 0.4014), ('vaccinessavelives', 0.4008)]\n",
      "[('covidvaccination', 0.5004), ('covid19vaccines', 0.4498), ('covid19ncancer', 0.4432), ('vaccinesforall', 0.4418), ('covid19bc', 0.439)]\n",
      "[('foxnews', 0.4143), ('facebook', 0.3762), ('cbsnews', 0.3566), ('news', 0.3401), ('reporting', 0.3225)]\n",
      "[('covid19vaccineupdates', 0.499), ('covid19vaccines', 0.4338), ('vaccineupdates', 0.4196), ('coronavirusupdate', 0.4037), ('coronavirusupdates', 0.4027)]\n",
      "[('hospitalizations', 0.4673), ('hospitalization', 0.4352), ('hospitalised', 0.4109), ('hospitalisation', 0.4105), ('vaccinehesitancy', 0.4074)]\n",
      "[('getvaccinated', 0.422), ('vaccine', 0.3994), ('vaccination', 0.3945), ('vaccineequity', 0.3912), ('vaccinated', 0.391)]\n",
      "[('covidvaccination', 0.5352), ('vaccinations', 0.5139), ('vaccination', 0.5123), ('covid19vaccination', 0.5117), ('vaccinationrolloutsa', 0.5076)]\n",
      "[('covid19vaccination', 0.5076), ('covidvaccination', 0.4949), ('vaccineboostershots', 0.4584), ('vaccinessavelives', 0.4544), ('coronaviruspandemic', 0.4536)]\n",
      "[('vaccination', 0.4612), ('vaccinations', 0.4518), ('vaccinated', 0.4401), ('vaccine', 0.4184), ('vaccinequity', 0.4136)]\n",
      "[('covidvaccinations', 0.5585), ('covidvaccination', 0.5396), ('covid19', 0.4785), ('covid_19', 0.4693), ('covid19nsw', 0.4674)]\n",
      "[('fda', 0.4076), ('covidvaccines', 0.3995), ('covid', 0.3937), ('covid_19', 0.3904), ('us_fda', 0.388)]\n",
      "[('covid19vaccination', 0.4352), ('covid19vic', 0.3834), ('covid19', 0.3797), ('covid19malaysia', 0.3653), ('epidemic', 0.3583)]\n",
      "[('covid19vaccination', 0.5221), ('covid__19', 0.4954), ('covid_19', 0.4886), ('covid19updates', 0.4612), ('covid19pandemic', 0.4611)]\n",
      "[('covid19', 0.5292), ('covid19nsw', 0.5278), ('covid19vic', 0.5066), ('covid19aus', 0.5038), ('rwanda_dv2021', 0.499)]\n",
      "[('coronavirus', 0.5505), ('covid_19', 0.4468), ('covid', 0.4459), ('covid19pandemic', 0.4298), ('coviddenial', 0.4233)]\n",
      "[('vaccinations', 0.4204), ('vaccines', 0.4198), ('vaccinessavelives', 0.4134), ('vaccinated', 0.4083), ('vaccination', 0.4065)]\n",
      "[('corona', 0.3656), ('coronavirus', 0.3303), ('vaxxers', 0.295), ('tacos', 0.2929), ('inside', 0.2833)]\n",
      "[('covidvaccinations', 0.501), ('covidvaccination', 0.4757), ('vaccinehesitancy', 0.4718), ('covid_19_canada', 0.4642), ('mandatoryvaccination', 0.447)]\n"
     ]
    }
   ],
   "source": [
    "# get important words\n",
    "vaccine_terms = 'shot|vaccine|vacine|vacines|vaccines|vaccinate|vaccination|vaccinations|vaccinated|vaccinating|vaxxed|vaxx|vax|\\\n",
    "unvaccinated|unvaxxed|antivaxx|antivaccination|anti|\\\n",
    "moderna|pfizer|j&j|immune|immunize|immunizes|immunized|immunization|immunizations|covid-19|covid|covidvaccination|covid19|covid19vaccination'\n",
    "vaccine_terms_list = vaccine_terms.split('|')\n",
    "\n",
    "for i in range(20):\n",
    "    corpus = list(df[df['community'] == i]['text'])\n",
    "    doc = ' '.join(corpus)\n",
    "    querywords = doc.split()\n",
    "    resultwords  = [word for word in querywords if word.lower() not in vaccine_terms_list]\n",
    "    result = ' '.join(resultwords)\n",
    "\n",
    "    kw_model = KeyBERT()\n",
    "    keywords = kw_model.extract_keywords(result)\n",
    "    print(kw_model.extract_keywords(result, keyphrase_ngram_range=(1, 1), stop_words=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aqxrd4t4r-Ay"
   },
   "outputs": [],
   "source": [
    "# LDA model\n",
    "# https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "stemmer = SnowballStemmer('english')\n",
    "# nltk.download('wordnet')\n",
    "# !pip install PyStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yhSDt2f6ucWi"
   },
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtnImo4Nug3l",
    "outputId": "96d80dda-6cf6-432b-fe3c-89072a8141f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ottawa, hospit, queensway, carleton, hospit, ...\n",
       "1    [facebook, say, post, cast, doubt, covid, vacc...\n",
       "2    [vaccin, peopl, appear, get, coronavirus, surp...\n",
       "3    [sweet, republican, booster, covid, shoot, tod...\n",
       "4                [beccaturmo, anti, https, hktaeylseq]\n",
       "5    [univers, virginia, disenrol, student, compli,...\n",
       "6    [scientist, blast, biden, administr, push, chi...\n",
       "7    [india, report, covid, case, recoveri, death, ...\n",
       "8    [look, edg, trumpism, trump, recommend, covid,...\n",
       "9    [month, warn, ivermectin, ineffect, danger, cu...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = df['text'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daT8ti5uuqzs",
    "outputId": "907cbc72-b63e-49d8-d94d-cc52f4f44d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 carleton\n",
      "1 covid\n",
      "2 hospit\n",
      "3 https\n",
      "4 make\n",
      "5 mandatori\n",
      "6 montfort\n",
      "7 ottawa\n",
      "8 queensway\n",
      "9 staff\n",
      "10 tsxs\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UEbgkEMLwRqC"
   },
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "b98YeLPrwbV0"
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zr8Lht_whDh",
    "outputId": "e3ac5620-f124-4c77-f79e-15952f9276df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.3373876197807154),\n",
      " (1, 0.5283198025765363),\n",
      " (2, 0.17545239503969073),\n",
      " (3, 0.21109818096069147),\n",
      " (4, 0.3373876197807154),\n",
      " (5, 0.31801676794533873),\n",
      " (6, 0.3373876197807154),\n",
      " (7, 0.22460004577636714),\n",
      " (8, 0.337807218133774),\n",
      " (9, 0.1958249765762748)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "U9L0ohVLwl9P"
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=20, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDae1Cyxwphc",
    "outputId": "20794a6b-cd6e-4b44-b49c-edd7b31a5307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.058*\"help\" + 0.047*\"confid\" + 0.043*\"mileston\" + 0.042*\"month\" + 0.034*\"emerg\" + 0.032*\"public\" + 0.029*\"tywbnlfj\" + 0.024*\"know\" + 0.021*\"author\" + 0.019*\"shoot\"\n",
      "Topic: 1 \n",
      "Words: 0.049*\"lift\" + 0.043*\"unvaccin\" + 0.040*\"peopl\" + 0.023*\"opportun\" + 0.022*\"fulli\" + 0.019*\"mandat\" + 0.017*\"govern\" + 0.016*\"constitut\" + 0.016*\"nation\" + 0.015*\"certif\"\n",
      "Topic: 2 \n",
      "Words: 0.453*\"today\" + 0.055*\"life\" + 0.038*\"booster\" + 0.029*\"shoot\" + 0.022*\"gladi\" + 0.022*\"berejiklian\" + 0.019*\"elig\" + 0.016*\"polit\" + 0.016*\"australia\" + 0.016*\"popul\"\n",
      "Topic: 3 \n",
      "Words: 0.040*\"caus\" + 0.040*\"long\" + 0.031*\"term\" + 0.028*\"review\" + 0.023*\"great\" + 0.022*\"cell\" + 0.020*\"children\" + 0.020*\"open\" + 0.020*\"start\" + 0.019*\"late\"\n",
      "Topic: 4 \n",
      "Words: 0.100*\"tweet\" + 0.056*\"american\" + 0.038*\"peopl\" + 0.034*\"old\" + 0.031*\"research\" + 0.023*\"highest\" + 0.019*\"flapol\" + 0.018*\"citizen\" + 0.018*\"afghanistan\" + 0.018*\"glad\"\n",
      "Topic: 5 \n",
      "Words: 0.020*\"young\" + 0.020*\"get\" + 0.020*\"appoint\" + 0.020*\"children\" + 0.019*\"safe\" + 0.018*\"kenya\" + 0.016*\"help\" + 0.014*\"age\" + 0.014*\"household\" + 0.014*\"jab\"\n",
      "Topic: 6 \n",
      "Words: 0.049*\"violat\" + 0.031*\"twitter\" + 0.030*\"religi\" + 0.025*\"mandat\" + 0.024*\"result\" + 0.024*\"act\" + 0.022*\"desanti\" + 0.022*\"right\" + 0.022*\"experi\" + 0.022*\"blast\"\n",
      "Topic: 7 \n",
      "Words: 0.088*\"process\" + 0.041*\"mask\" + 0.039*\"school\" + 0.034*\"sourc\" + 0.032*\"mandat\" + 0.026*\"replac\" + 0.026*\"tell\" + 0.023*\"hospit\" + 0.021*\"peopl\" + 0.021*\"largest\"\n",
      "Topic: 8 \n",
      "Words: 0.183*\"approv\" + 0.169*\"pfizer\" + 0.095*\"grant\" + 0.067*\"break\" + 0.038*\"biontech\" + 0.034*\"offici\" + 0.031*\"news\" + 0.028*\"huge\" + 0.023*\"familiar\" + 0.021*\"make\"\n",
      "Topic: 9 \n",
      "Words: 0.050*\"feder\" + 0.040*\"case\" + 0.034*\"dose\" + 0.031*\"death\" + 0.023*\"public\" + 0.019*\"health\" + 0.017*\"york\" + 0.017*\"total\" + 0.017*\"report\" + 0.014*\"receiv\"\n",
      "Topic: 10 \n",
      "Words: 0.046*\"test\" + 0.037*\"consequ\" + 0.024*\"probabl\" + 0.023*\"posit\" + 0.022*\"path\" + 0.020*\"requir\" + 0.017*\"continu\" + 0.017*\"hear\" + 0.017*\"proof\" + 0.015*\"know\"\n",
      "Topic: 11 \n",
      "Words: 0.130*\"encourag\" + 0.051*\"massiv\" + 0.049*\"trump\" + 0.044*\"alabama\" + 0.044*\"look\" + 0.042*\"anti\" + 0.035*\"recommend\" + 0.034*\"ralli\" + 0.031*\"crowd\" + 0.031*\"boo\"\n",
      "Topic: 12 \n",
      "Words: 0.042*\"lose\" + 0.036*\"refus\" + 0.032*\"persuad\" + 0.030*\"hour\" + 0.027*\"hesit\" + 0.026*\"florida\" + 0.026*\"son\" + 0.022*\"peopl\" + 0.019*\"health\" + 0.018*\"pandem\"\n",
      "Topic: 13 \n",
      "Words: 0.082*\"teacher\" + 0.059*\"shoot\" + 0.058*\"restrict\" + 0.044*\"dog\" + 0.041*\"dead\" + 0.034*\"rescu\" + 0.032*\"arm\" + 0.029*\"fail\" + 0.027*\"control\" + 0.026*\"educ\"\n",
      "Topic: 14 \n",
      "Words: 0.038*\"peopl\" + 0.031*\"coronavirus\" + 0.029*\"financi\" + 0.026*\"infect\" + 0.023*\"delta\" + 0.021*\"protect\" + 0.018*\"virus\" + 0.018*\"high\" + 0.018*\"potenti\" + 0.017*\"like\"\n",
      "Topic: 15 \n",
      "Words: 0.056*\"social\" + 0.043*\"announc\" + 0.036*\"covidnsw\" + 0.033*\"state\" + 0.029*\"return\" + 0.028*\"distanc\" + 0.028*\"remain\" + 0.027*\"observ\" + 0.027*\"good\" + 0.019*\"chang\"\n",
      "Topic: 16 \n",
      "Words: 0.120*\"coronavirus\" + 0.077*\"mean\" + 0.052*\"bqyq\" + 0.052*\"okyp\" + 0.048*\"women\" + 0.039*\"want\" + 0.039*\"know\" + 0.038*\"pregnant\" + 0.032*\"have\" + 0.030*\"think\"\n",
      "Topic: 17 \n",
      "Words: 0.131*\"get\" + 0.104*\"die\" + 0.075*\"risk\" + 0.059*\"decemb\" + 0.053*\"host\" + 0.052*\"radio\" + 0.046*\"conserv\" + 0.045*\"valentin\" + 0.044*\"phil\" + 0.039*\"heart\"\n",
      "Topic: 18 \n",
      "Words: 0.101*\"regul\" + 0.046*\"shot\" + 0.042*\"lengthi\" + 0.038*\"accord\" + 0.036*\"moderna\" + 0.027*\"approv\" + 0.027*\"plan\" + 0.027*\"trial\" + 0.026*\"govern\" + 0.026*\"death\"\n",
      "Topic: 19 \n",
      "Words: 0.131*\"approv\" + 0.114*\"year\" + 0.111*\"prevent\" + 0.110*\"older\" + 0.108*\"diseas\" + 0.107*\"individu\" + 0.099*\"ioqsxxv\" + 0.021*\"washington\" + 0.017*\"drug\" + 0.014*\"administr\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0qy9nBdwwGa",
    "outputId": "0487812a-370a-4329-8c65-a53be4d53fd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.114*\"pfizer\" + 0.104*\"grant\" + 0.092*\"approv\" + 0.090*\"break\" + 0.069*\"teacher\" + 0.037*\"aim\" + 0.036*\"monday\" + 0.032*\"educ\" + 0.031*\"declin\" + 0.030*\"fail\"\n",
      "Topic: 1 Word: 0.028*\"opportun\" + 0.027*\"vxsxuitjow\" + 0.025*\"fulli\" + 0.023*\"major\" + 0.022*\"encourag\" + 0.018*\"mandat\" + 0.016*\"mean\" + 0.015*\"certif\" + 0.014*\"pfizer\" + 0.012*\"get\"\n",
      "Topic: 2 Word: 0.045*\"boo\" + 0.045*\"trump\" + 0.043*\"crowd\" + 0.042*\"ralli\" + 0.042*\"alabama\" + 0.039*\"donald\" + 0.033*\"folk\" + 0.033*\"recommend\" + 0.032*\"board\" + 0.032*\"trumpism\"\n",
      "Topic: 3 Word: 0.028*\"moderna\" + 0.024*\"liter\" + 0.023*\"financi\" + 0.023*\"qinksg\" + 0.023*\"answer\" + 0.023*\"trial\" + 0.023*\"ahead\" + 0.023*\"pharma\" + 0.023*\"complet\" + 0.022*\"shot\"\n",
      "Topic: 4 Word: 0.074*\"offici\" + 0.046*\"process\" + 0.044*\"huge\" + 0.037*\"grant\" + 0.035*\"approv\" + 0.028*\"news\" + 0.028*\"author\" + 0.027*\"feder\" + 0.021*\"emerg\" + 0.021*\"make\"\n",
      "Topic: 5 Word: 0.110*\"ioqsxxv\" + 0.103*\"older\" + 0.103*\"individu\" + 0.101*\"diseas\" + 0.095*\"prevent\" + 0.090*\"today\" + 0.085*\"year\" + 0.054*\"approv\" + 0.007*\"infect\" + 0.005*\"connect\"\n",
      "Topic: 6 Word: 0.022*\"york\" + 0.020*\"unvaccin\" + 0.014*\"mandatori\" + 0.013*\"excus\" + 0.012*\"option\" + 0.012*\"night\" + 0.012*\"sean\" + 0.012*\"penn\" + 0.011*\"peopl\" + 0.011*\"call\"\n",
      "Topic: 7 Word: 0.103*\"nail\" + 0.021*\"largest\" + 0.018*\"good\" + 0.017*\"return\" + 0.016*\"zohsncivar\" + 0.016*\"control\" + 0.016*\"case\" + 0.016*\"announc\" + 0.016*\"normal\" + 0.015*\"remain\"\n",
      "Topic: 8 Word: 0.031*\"hesit\" + 0.030*\"coronavirus\" + 0.029*\"chang\" + 0.028*\"repeat\" + 0.027*\"potenti\" + 0.026*\"downplay\" + 0.024*\"hospit\" + 0.022*\"think\" + 0.021*\"virus\" + 0.021*\"sound\"\n",
      "Topic: 9 Word: 0.053*\"son\" + 0.050*\"hour\" + 0.050*\"lose\" + 0.042*\"span\" + 0.039*\"florida\" + 0.037*\"refus\" + 0.033*\"yahoo\" + 0.032*\"wszxfwwc\" + 0.021*\"cell\" + 0.017*\"put\"\n",
      "Topic: 10 Word: 0.066*\"shoot\" + 0.057*\"dog\" + 0.053*\"rescu\" + 0.050*\"restrict\" + 0.040*\"dead\" + 0.035*\"council\" + 0.032*\"polit\" + 0.030*\"replac\" + 0.030*\"republican\" + 0.029*\"sweet\"\n",
      "Topic: 11 Word: 0.025*\"scoop\" + 0.022*\"term\" + 0.021*\"consequ\" + 0.017*\"hear\" + 0.017*\"long\" + 0.013*\"pregnant\" + 0.012*\"probabl\" + 0.012*\"caus\" + 0.012*\"past\" + 0.011*\"fact\"\n",
      "Topic: 12 Word: 0.015*\"walk\" + 0.012*\"august\" + 0.012*\"talk\" + 0.011*\"suck\" + 0.010*\"receiv\" + 0.010*\"promot\" + 0.010*\"thank\" + 0.010*\"dose\" + 0.009*\"citizen\" + 0.009*\"million\"\n",
      "Topic: 13 Word: 0.021*\"path\" + 0.020*\"wear\" + 0.020*\"battl\" + 0.019*\"storm\" + 0.019*\"observ\" + 0.018*\"forget\" + 0.018*\"catch\" + 0.017*\"henri\" + 0.017*\"variant\" + 0.016*\"mask\"\n",
      "Topic: 14 Word: 0.053*\"biontech\" + 0.045*\"pfizer\" + 0.045*\"regul\" + 0.042*\"approv\" + 0.041*\"grant\" + 0.037*\"lengthi\" + 0.031*\"sourc\" + 0.030*\"familiar\" + 0.027*\"confid\" + 0.021*\"open\"\n",
      "Topic: 15 Word: 0.029*\"lift\" + 0.029*\"mileston\" + 0.023*\"door\" + 0.017*\"arm\" + 0.016*\"shot\" + 0.014*\"rate\" + 0.013*\"peopl\" + 0.012*\"ill\" + 0.012*\"high\" + 0.010*\"twitter\"\n",
      "Topic: 16 Word: 0.021*\"requir\" + 0.018*\"test\" + 0.015*\"mandat\" + 0.015*\"invari\" + 0.014*\"violat\" + 0.013*\"school\" + 0.013*\"staffer\" + 0.012*\"posit\" + 0.012*\"religi\" + 0.011*\"proof\"\n",
      "Topic: 17 Word: 0.025*\"distanc\" + 0.018*\"floridian\" + 0.017*\"tune\" + 0.010*\"monoclon\" + 0.010*\"treatment\" + 0.010*\"antibodi\" + 0.010*\"state\" + 0.009*\"serv\" + 0.009*\"visit\" + 0.009*\"inform\"\n",
      "Topic: 18 Word: 0.097*\"get\" + 0.072*\"risk\" + 0.067*\"die\" + 0.040*\"radio\" + 0.040*\"conserv\" + 0.039*\"host\" + 0.039*\"paralysi\" + 0.039*\"phil\" + 0.039*\"abvji\" + 0.038*\"valentin\"\n",
      "Topic: 19 Word: 0.098*\"washington\" + 0.081*\"regul\" + 0.056*\"pfizer\" + 0.049*\"approv\" + 0.041*\"break\" + 0.038*\"drug\" + 0.031*\"food\" + 0.030*\"administr\" + 0.020*\"comirnati\" + 0.019*\"market\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=20, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fqKUK7UxBg2",
    "outputId": "a5fe38c0-8232-4e76-d6a2-62d47d72d0a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ottawa, hospital, queensway, carleton, hospit...\n",
       "1    [facebook, says, post, cast, doubt, covid, vac...\n",
       "2    [vaccinated, people, appear, getting, coronavi...\n",
       "3    [sweet, republican, booster, covid, shot, toda...\n",
       "4                [beccaturmo, anti, https, hktaeylseq]\n",
       "5    [university, virginia, disenrolls, students, c...\n",
       "6    [scientists, blasted, biden, administration, p...\n",
       "7    [india, reports, covid, cases, recoveries, dea...\n",
       "8    [looking, edge, trumpism, trump, recommends, c...\n",
       "9    [months, warning, ivermectin, ineffective, dan...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess version 2\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "processed_docs2 = df['text'].map(preprocess)\n",
    "processed_docs2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnKIi_kyyRNl",
    "outputId": "ce8f0606-8115-4d9c-eb11-aedd65993eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 carleton\n",
      "1 covid\n",
      "2 hospit\n",
      "3 https\n",
      "4 make\n",
      "5 mandatori\n",
      "6 montfort\n",
      "7 ottawa\n",
      "8 queensway\n",
      "9 staff\n",
      "10 tsxs\n"
     ]
    }
   ],
   "source": [
    "dictionary2 = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary2.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "0YG3kEh7ybaL"
   },
   "outputs": [],
   "source": [
    "dictionary2.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "bow_corpus2 = [dictionary2.doc2bow(doc) for doc in processed_docs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaCcmCo7ykdz",
    "outputId": "229048c1-a9d5-49ea-809f-bec2e84b6011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.41678611795725035),\n",
      " (4, 0.41678611795725035),\n",
      " (5, 0.39285666214841214),\n",
      " (6, 0.41678611795725035),\n",
      " (7, 0.27816499524810273),\n",
      " (8, 0.41730446172097885),\n",
      " (9, 0.2702089197017199)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf2 = models.TfidfModel(bow_corpus2)\n",
    "corpus_tfidf2 = tfidf2[bow_corpus2]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf2:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "cRnWiGLiyrdI"
   },
   "outputs": [],
   "source": [
    "lda_model2 = gensim.models.LdaMulticore(bow_corpus2, num_topics=20, id2word=dictionary2, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QV3GJbC8yvL2",
    "outputId": "1429260b-81b4-49b4-887b-900a57c574e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.416*\"today\" + 0.355*\"ioqsxxv\" + 0.063*\"life\" + 0.030*\"booster\" + 0.015*\"shot\" + 0.012*\"sweet\" + 0.011*\"republican\" + 0.006*\"save\" + 0.004*\"letter\" + 0.003*\"gold\"\n",
      "Topic: 1 \n",
      "Words: 0.087*\"moderna\" + 0.068*\"plan\" + 0.067*\"ahead\" + 0.065*\"pharma\" + 0.062*\"qinksg\" + 0.042*\"scoop\" + 0.031*\"review\" + 0.026*\"remain\" + 0.024*\"good\" + 0.024*\"state\"\n",
      "Topic: 2 \n",
      "Words: 0.180*\"process\" + 0.109*\"chief\" + 0.038*\"huge\" + 0.033*\"open\" + 0.022*\"clinic\" + 0.022*\"sunday\" + 0.022*\"time\" + 0.021*\"john\" + 0.020*\"august\" + 0.020*\"walk\"\n",
      "Topic: 3 \n",
      "Words: 0.396*\"pfizer\" + 0.086*\"biontech\" + 0.075*\"news\" + 0.054*\"familiar\" + 0.053*\"huge\" + 0.033*\"public\" + 0.027*\"lift\" + 0.026*\"help\" + 0.025*\"tywbnlfj\" + 0.021*\"monday\"\n",
      "Topic: 4 \n",
      "Words: 0.203*\"florida\" + 0.050*\"virus\" + 0.050*\"record\" + 0.046*\"come\" + 0.039*\"span\" + 0.039*\"blue\" + 0.035*\"state\" + 0.029*\"host\" + 0.029*\"week\" + 0.029*\"radio\"\n",
      "Topic: 5 \n",
      "Words: 0.126*\"yesterday\" + 0.115*\"meet\" + 0.078*\"storm\" + 0.059*\"late\" + 0.055*\"local\" + 0.045*\"actor\" + 0.035*\"night\" + 0.030*\"penn\" + 0.030*\"sean\" + 0.030*\"face\"\n",
      "Topic: 6 \n",
      "Words: 0.423*\"older\" + 0.107*\"shot\" + 0.041*\"dead\" + 0.025*\"great\" + 0.025*\"health\" + 0.021*\"council\" + 0.019*\"public\" + 0.015*\"close\" + 0.013*\"household\" + 0.012*\"half\"\n",
      "Topic: 7 \n",
      "Words: 0.090*\"need\" + 0.060*\"delta\" + 0.058*\"mask\" + 0.051*\"variant\" + 0.050*\"wear\" + 0.039*\"school\" + 0.039*\"path\" + 0.035*\"shelter\" + 0.035*\"social\" + 0.032*\"forget\"\n",
      "Topic: 8 \n",
      "Words: 0.066*\"year\" + 0.062*\"normal\" + 0.046*\"status\" + 0.033*\"breakthrough\" + 0.031*\"news\" + 0.031*\"sajid\" + 0.028*\"virus\" + 0.027*\"start\" + 0.025*\"adult\" + 0.025*\"video\"\n",
      "Topic: 9 \n",
      "Words: 0.226*\"coronavirus\" + 0.087*\"mean\" + 0.077*\"know\" + 0.064*\"want\" + 0.061*\"think\" + 0.056*\"okyp\" + 0.056*\"bqyq\" + 0.051*\"death\" + 0.042*\"right\" + 0.040*\"vxsxuitjow\"\n",
      "Topic: 10 \n",
      "Words: 0.148*\"washington\" + 0.083*\"young\" + 0.065*\"help\" + 0.035*\"health\" + 0.035*\"area\" + 0.022*\"long\" + 0.021*\"johannesburg\" + 0.021*\"connect\" + 0.020*\"bvnxf\" + 0.020*\"tgbp\"\n",
      "Topic: 11 \n",
      "Words: 0.094*\"control\" + 0.044*\"australia\" + 0.039*\"total\" + 0.032*\"covidnsw\" + 0.032*\"better\" + 0.026*\"staff\" + 0.024*\"point\" + 0.024*\"state\" + 0.022*\"prove\" + 0.022*\"coronavirus\"\n",
      "Topic: 12 \n",
      "Words: 0.107*\"long\" + 0.081*\"term\" + 0.059*\"york\" + 0.048*\"social\" + 0.041*\"dose\" + 0.039*\"fact\" + 0.038*\"return\" + 0.026*\"covidnsw\" + 0.025*\"proof\" + 0.025*\"month\"\n",
      "Topic: 13 \n",
      "Words: 0.144*\"anti\" + 0.059*\"talk\" + 0.048*\"freedom\" + 0.038*\"state\" + 0.035*\"lockdown\" + 0.034*\"tort\" + 0.034*\"yahoo\" + 0.031*\"wszxfwwc\" + 0.026*\"woman\" + 0.023*\"queensland\"\n",
      "Topic: 14 \n",
      "Words: 0.062*\"million\" + 0.053*\"data\" + 0.040*\"largest\" + 0.037*\"seek\" + 0.030*\"time\" + 0.030*\"test\" + 0.026*\"girl\" + 0.025*\"panic\" + 0.025*\"rice\" + 0.023*\"coronavirus\"\n",
      "Topic: 15 \n",
      "Words: 0.061*\"number\" + 0.061*\"major\" + 0.061*\"past\" + 0.051*\"children\" + 0.043*\"treatment\" + 0.035*\"month\" + 0.029*\"kenya\" + 0.027*\"nation\" + 0.026*\"child\" + 0.026*\"friday\"\n",
      "Topic: 16 \n",
      "Words: 0.135*\"pregnant\" + 0.085*\"trump\" + 0.078*\"alabama\" + 0.070*\"safe\" + 0.052*\"crowd\" + 0.052*\"women\" + 0.050*\"donald\" + 0.039*\"board\" + 0.033*\"lethal\" + 0.033*\"trumpism\"\n",
      "Topic: 17 \n",
      "Words: 0.162*\"drug\" + 0.127*\"food\" + 0.069*\"subject\" + 0.041*\"read\" + 0.029*\"vincent\" + 0.028*\"moderna\" + 0.025*\"eaqt\" + 0.025*\"covax\" + 0.025*\"prevent\" + 0.023*\"human\"\n",
      "Topic: 18 \n",
      "Words: 0.065*\"high\" + 0.054*\"rate\" + 0.053*\"dose\" + 0.043*\"coronavirus\" + 0.032*\"world\" + 0.027*\"total\" + 0.026*\"research\" + 0.025*\"israel\" + 0.023*\"delta\" + 0.021*\"wide\"\n",
      "Topic: 19 \n",
      "Words: 0.230*\"risk\" + 0.125*\"radio\" + 0.122*\"host\" + 0.099*\"phil\" + 0.098*\"heart\" + 0.093*\"dead\" + 0.092*\"attack\" + 0.015*\"easier\" + 0.009*\"walk\" + 0.008*\"malaysian\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model2.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-axgNh9_0Fbk",
    "outputId": "738742b1-5520-4f8a-9ede-98573ca9ce85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: ['today', 'ioqsxxv', 'life', 'booster', 'shot', 'sweet', 'republican', 'save', 'letter', 'gold']\n",
      "Topic: 1 \n",
      "Words: ['moderna', 'plan', 'ahead', 'pharma', 'qinksg', 'scoop', 'review', 'remain', 'good', 'state']\n",
      "Topic: 2 \n",
      "Words: ['process', 'chief', 'huge', 'open', 'clinic', 'sunday', 'time', 'john', 'august', 'walk']\n",
      "Topic: 3 \n",
      "Words: ['pfizer', 'biontech', 'news', 'familiar', 'huge', 'public', 'lift', 'help', 'tywbnlfj', 'monday']\n",
      "Topic: 4 \n",
      "Words: ['florida', 'virus', 'record', 'come', 'span', 'blue', 'state', 'host', 'week', 'radio']\n",
      "Topic: 5 \n",
      "Words: ['yesterday', 'meet', 'storm', 'late', 'local', 'actor', 'night', 'penn', 'sean', 'face']\n",
      "Topic: 6 \n",
      "Words: ['older', 'shot', 'dead', 'great', 'health', 'council', 'public', 'close', 'household', 'half']\n",
      "Topic: 7 \n",
      "Words: ['need', 'delta', 'mask', 'variant', 'wear', 'school', 'path', 'shelter', 'social', 'forget']\n",
      "Topic: 8 \n",
      "Words: ['year', 'normal', 'status', 'breakthrough', 'news', 'sajid', 'virus', 'start', 'adult', 'video']\n",
      "Topic: 9 \n",
      "Words: ['coronavirus', 'mean', 'know', 'want', 'think', 'okyp', 'bqyq', 'death', 'right', 'vxsxuitjow']\n",
      "Topic: 10 \n",
      "Words: ['washington', 'young', 'help', 'health', 'area', 'long', 'johannesburg', 'connect', 'bvnxf', 'tgbp']\n",
      "Topic: 11 \n",
      "Words: ['control', 'australia', 'total', 'covidnsw', 'better', 'staff', 'point', 'state', 'prove', 'coronavirus']\n",
      "Topic: 12 \n",
      "Words: ['long', 'term', 'york', 'social', 'dose', 'fact', 'return', 'covidnsw', 'proof', 'month']\n",
      "Topic: 13 \n",
      "Words: ['anti', 'talk', 'freedom', 'state', 'lockdown', 'tort', 'yahoo', 'wszxfwwc', 'woman', 'queensland']\n",
      "Topic: 14 \n",
      "Words: ['million', 'data', 'largest', 'seek', 'time', 'test', 'girl', 'panic', 'rice', 'coronavirus']\n",
      "Topic: 15 \n",
      "Words: ['number', 'major', 'past', 'children', 'treatment', 'month', 'kenya', 'nation', 'child', 'friday']\n",
      "Topic: 16 \n",
      "Words: ['pregnant', 'trump', 'alabama', 'safe', 'crowd', 'women', 'donald', 'board', 'lethal', 'trumpism']\n",
      "Topic: 17 \n",
      "Words: ['drug', 'food', 'subject', 'read', 'vincent', 'moderna', 'eaqt', 'covax', 'prevent', 'human']\n",
      "Topic: 18 \n",
      "Words: ['high', 'rate', 'dose', 'coronavirus', 'world', 'total', 'research', 'israel', 'delta', 'wide']\n",
      "Topic: 19 \n",
      "Words: ['risk', 'radio', 'host', 'phil', 'heart', 'dead', 'attack', 'easier', 'walk', 'malaysian']\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model2.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, re.findall('\"([^\"]*)\"', topic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldqkSM4Wyyc_",
    "outputId": "e94f15ba-a82b-4e1d-e4bd-91541de79e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.031*\"forget\" + 0.031*\"breakthrough\" + 0.023*\"facebook\" + 0.022*\"post\" + 0.021*\"delta\" + 0.020*\"virus\" + 0.019*\"march\" + 0.019*\"platform\" + 0.017*\"storm\" + 0.017*\"control\"\n",
      "Topic: 1 Word: 0.072*\"moderna\" + 0.061*\"plan\" + 0.060*\"qinksg\" + 0.058*\"pharma\" + 0.058*\"ahead\" + 0.058*\"chief\" + 0.026*\"treatment\" + 0.017*\"visit\" + 0.014*\"rzgx\" + 0.014*\"ytgs\"\n",
      "Topic: 2 Word: 0.045*\"fact\" + 0.036*\"high\" + 0.034*\"rate\" + 0.032*\"thought\" + 0.030*\"concern\" + 0.029*\"appear\" + 0.026*\"ayryynmipm\" + 0.025*\"blast\" + 0.021*\"test\" + 0.020*\"proof\"\n",
      "Topic: 3 Word: 0.069*\"help\" + 0.059*\"public\" + 0.036*\"tywbnlfj\" + 0.027*\"pfizer\" + 0.025*\"shot\" + 0.023*\"area\" + 0.018*\"johannesburg\" + 0.018*\"connect\" + 0.018*\"tgbp\" + 0.018*\"bvnxf\"\n",
      "Topic: 4 Word: 0.238*\"ioqsxxv\" + 0.221*\"older\" + 0.211*\"today\" + 0.021*\"booster\" + 0.020*\"york\" + 0.016*\"sweet\" + 0.015*\"life\" + 0.014*\"republican\" + 0.011*\"shot\" + 0.005*\"unvax\"\n",
      "Topic: 5 Word: 0.076*\"tune\" + 0.068*\"virus\" + 0.055*\"cmcqrwal\" + 0.050*\"radio\" + 0.049*\"host\" + 0.049*\"phil\" + 0.034*\"wonder\" + 0.030*\"kaedaf\" + 0.027*\"victoria\" + 0.016*\"ontario\"\n",
      "Topic: 6 Word: 0.078*\"mean\" + 0.052*\"death\" + 0.050*\"right\" + 0.049*\"think\" + 0.045*\"want\" + 0.045*\"vxsxuitjow\" + 0.041*\"corona\" + 0.039*\"women\" + 0.039*\"rager\" + 0.039*\"ngre\"\n",
      "Topic: 7 Word: 0.176*\"biontech\" + 0.072*\"pfizer\" + 0.064*\"shot\" + 0.044*\"dead\" + 0.037*\"council\" + 0.037*\"coronavirus\" + 0.023*\"australian\" + 0.023*\"irwvdkfdpa\" + 0.020*\"aclohkh\" + 0.020*\"xvgavx\"\n",
      "Topic: 8 Word: 0.046*\"pfizer\" + 0.043*\"scoop\" + 0.043*\"bqyq\" + 0.043*\"okyp\" + 0.039*\"door\" + 0.032*\"subject\" + 0.029*\"major\" + 0.027*\"coronavirus\" + 0.022*\"ryzszyeh\" + 0.019*\"covidnsw\"\n",
      "Topic: 9 Word: 0.248*\"pfizer\" + 0.084*\"familiar\" + 0.070*\"monday\" + 0.026*\"news\" + 0.024*\"pregnant\" + 0.023*\"tvprzv\" + 0.023*\"path\" + 0.019*\"status\" + 0.019*\"seek\" + 0.015*\"girl\"\n",
      "Topic: 10 Word: 0.174*\"risk\" + 0.097*\"radio\" + 0.096*\"host\" + 0.095*\"yesterday\" + 0.091*\"attack\" + 0.091*\"meet\" + 0.090*\"phil\" + 0.090*\"heart\" + 0.082*\"dead\" + 0.004*\"function\"\n",
      "Topic: 11 Word: 0.041*\"social\" + 0.034*\"mask\" + 0.034*\"variant\" + 0.029*\"delta\" + 0.029*\"wear\" + 0.028*\"need\" + 0.024*\"henri\" + 0.021*\"shelter\" + 0.020*\"safe\" + 0.020*\"return\"\n",
      "Topic: 12 Word: 0.102*\"lift\" + 0.070*\"review\" + 0.055*\"actor\" + 0.041*\"face\" + 0.041*\"sean\" + 0.041*\"penn\" + 0.039*\"great\" + 0.037*\"tywbnlfj\" + 0.030*\"rnqxducr\" + 0.028*\"freedom\"\n",
      "Topic: 13 Word: 0.081*\"span\" + 0.072*\"florida\" + 0.058*\"yahoo\" + 0.056*\"wszxfwwc\" + 0.033*\"household\" + 0.016*\"trial\" + 0.015*\"class\" + 0.014*\"nation\" + 0.014*\"covaxin\" + 0.013*\"follow\"\n",
      "Topic: 14 Word: 0.027*\"young\" + 0.024*\"hear\" + 0.022*\"isfj\" + 0.022*\"uaqcu\" + 0.021*\"research\" + 0.018*\"think\" + 0.015*\"care\" + 0.014*\"year\" + 0.013*\"protect\" + 0.013*\"like\"\n",
      "Topic: 15 Word: 0.040*\"million\" + 0.026*\"berejiklian\" + 0.023*\"prove\" + 0.022*\"wide\" + 0.021*\"rice\" + 0.021*\"state\" + 0.020*\"knazqiloto\" + 0.020*\"delta\" + 0.017*\"twitter\" + 0.017*\"hope\"\n",
      "Topic: 16 Word: 0.101*\"trump\" + 0.097*\"alabama\" + 0.087*\"donald\" + 0.083*\"crowd\" + 0.073*\"board\" + 0.071*\"trumpism\" + 0.020*\"hxzmxs\" + 0.019*\"biden\" + 0.018*\"udmazi\" + 0.015*\"sept\"\n",
      "Topic: 17 Word: 0.061*\"long\" + 0.053*\"term\" + 0.036*\"dose\" + 0.031*\"close\" + 0.030*\"past\" + 0.028*\"month\" + 0.026*\"plateau\" + 0.024*\"older\" + 0.024*\"israel\" + 0.019*\"taiwan\"\n",
      "Topic: 18 Word: 0.079*\"drug\" + 0.052*\"food\" + 0.036*\"school\" + 0.029*\"press\" + 0.023*\"pxnr\" + 0.022*\"public\" + 0.019*\"treat\" + 0.019*\"prevent\" + 0.018*\"anti\" + 0.017*\"account\"\n",
      "Topic: 19 Word: 0.140*\"washington\" + 0.108*\"huge\" + 0.098*\"process\" + 0.095*\"pfizer\" + 0.083*\"news\" + 0.023*\"eaqt\" + 0.022*\"local\" + 0.018*\"food\" + 0.018*\"drug\" + 0.017*\"night\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf2 = gensim.models.LdaMulticore(corpus_tfidf2, num_topics=20, id2word=dictionary2, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf2.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vINn4a9Yy3b1",
    "outputId": "2c8a4b94-c4aa-487a-e28a-3217817c3163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: ['forget', 'breakthrough', 'facebook', 'post', 'delta', 'virus', 'march', 'platform', 'storm', 'control']\n",
      "Topic: 1 Word: ['moderna', 'plan', 'qinksg', 'pharma', 'ahead', 'chief', 'treatment', 'visit', 'rzgx', 'ytgs']\n",
      "Topic: 2 Word: ['fact', 'high', 'rate', 'thought', 'concern', 'appear', 'ayryynmipm', 'blast', 'test', 'proof']\n",
      "Topic: 3 Word: ['help', 'public', 'tywbnlfj', 'pfizer', 'shot', 'area', 'johannesburg', 'connect', 'tgbp', 'bvnxf']\n",
      "Topic: 4 Word: ['ioqsxxv', 'older', 'today', 'booster', 'york', 'sweet', 'life', 'republican', 'shot', 'unvax']\n",
      "Topic: 5 Word: ['tune', 'virus', 'cmcqrwal', 'radio', 'host', 'phil', 'wonder', 'kaedaf', 'victoria', 'ontario']\n",
      "Topic: 6 Word: ['mean', 'death', 'right', 'think', 'want', 'vxsxuitjow', 'corona', 'women', 'rager', 'ngre']\n",
      "Topic: 7 Word: ['biontech', 'pfizer', 'shot', 'dead', 'council', 'coronavirus', 'australian', 'irwvdkfdpa', 'aclohkh', 'xvgavx']\n",
      "Topic: 8 Word: ['pfizer', 'scoop', 'bqyq', 'okyp', 'door', 'subject', 'major', 'coronavirus', 'ryzszyeh', 'covidnsw']\n",
      "Topic: 9 Word: ['pfizer', 'familiar', 'monday', 'news', 'pregnant', 'tvprzv', 'path', 'status', 'seek', 'girl']\n",
      "Topic: 10 Word: ['risk', 'radio', 'host', 'yesterday', 'attack', 'meet', 'phil', 'heart', 'dead', 'function']\n",
      "Topic: 11 Word: ['social', 'mask', 'variant', 'delta', 'wear', 'need', 'henri', 'shelter', 'safe', 'return']\n",
      "Topic: 12 Word: ['lift', 'review', 'actor', 'face', 'sean', 'penn', 'great', 'tywbnlfj', 'rnqxducr', 'freedom']\n",
      "Topic: 13 Word: ['span', 'florida', 'yahoo', 'wszxfwwc', 'household', 'trial', 'class', 'nation', 'covaxin', 'follow']\n",
      "Topic: 14 Word: ['young', 'hear', 'isfj', 'uaqcu', 'research', 'think', 'care', 'year', 'protect', 'like']\n",
      "Topic: 15 Word: ['million', 'berejiklian', 'prove', 'wide', 'rice', 'state', 'knazqiloto', 'delta', 'twitter', 'hope']\n",
      "Topic: 16 Word: ['trump', 'alabama', 'donald', 'crowd', 'board', 'trumpism', 'hxzmxs', 'biden', 'udmazi', 'sept']\n",
      "Topic: 17 Word: ['long', 'term', 'dose', 'close', 'past', 'month', 'plateau', 'older', 'israel', 'taiwan']\n",
      "Topic: 18 Word: ['drug', 'food', 'school', 'press', 'pxnr', 'public', 'treat', 'prevent', 'anti', 'account']\n",
      "Topic: 19 Word: ['washington', 'huge', 'process', 'pfizer', 'news', 'eaqt', 'local', 'food', 'drug', 'night']\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf2.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, re.findall('\"([^\"]*)\"', topic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_islmjxzljh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Math 168 Project Topic Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
