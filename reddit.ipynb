{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37556b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "import datetime as dt\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19df549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old code to grab tweet ids -- idk might be useful later\n",
    "# for i in range(10, 32):\n",
    "#     url = f\"https://github.com/thepanacealab/covid19_twitter/blob/master/dailies/2021-08-{i}/2021-08-{i}-dataset.tsv.gz?raw=true\"\n",
    "#     tweet = pd.read_csv(url, compression = 'gzip', delimiter = '\\t')\n",
    "#     tweet = tweet[tweet[\"lang\"] == 'en']\n",
    "#     print(tweet.shape)\n",
    "#     tweet['tweet_id'].to_csv(f\"C:\\\\Users\\chris\\\\Downloads\\\\filtered_tweet_ids\\\\08_{i}.csv\", index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856e7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525073f",
   "metadata": {},
   "source": [
    "list of subreddits:  \n",
    "* antivaccine now a space jam sub?\n",
    "* trueantivaccination (quarantined) done\n",
    "* Vaccines done\n",
    "* CovidVaccine done\n",
    "* CovidVaccinated done\n",
    "* AntiVaxxers done\n",
    "* conspiracy* \n",
    "* conspiracytheories* \n",
    "* NoNewNormal banned :( = prob a lot less antivaxx posts\n",
    "* conspiracy_commons* \n",
    "* COVID19* done\n",
    "* COVID private\n",
    "* coronavirus* done\n",
    "* conservative* done\n",
    "* worldnews* done\n",
    "* news* \n",
    "\n",
    "\\* = search terms used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b3a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_terms = 'covid|covid19|c19|corona|coronavirus|CoV-2|pandemic|variant|delta|virus|infection|infect|fauci|cdc|fda|mandate'\n",
    "vaccine_terms = 'shot|vaccine|vacine|vacines|vaccines|vaccinate|vaccination|vaccinations|vaccinated|vaccinating|vaxxed|vaxx|vax|\\\n",
    "unvaccinated|unvaxxed|antivaxx|antivaccination|anti|\\\n",
    "moderna|pfizer|J&J|immune|immunize|immunizes|immunized|immunization|immunizations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb0ffa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch=int(dt.datetime(2021, 8, 10).timestamp()) #searches for posts after midnight 8/10\n",
    "end_epoch = int(dt.datetime(2021, 9, 1).timestamp()) #stops getting posts at midnight 9/1\n",
    "ids = list(api.search_submissions(after=start_epoch, #makes list of psaw submission objects\n",
    "                                  before = end_epoch,\n",
    "                                  filter = ['id'],\n",
    "                                  title = covid_terms+vaccine_terms,\n",
    "                                  subreddit = 'news'))#searches for keywords in title only)\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82412697",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\chris\\\\Documents\\\\Math168Project\\\\no_search.csv\", 'a', encoding=\"utf-8\") as file:\n",
    "    #setting up the csv file\n",
    "    headers = ['ID', 'Date_utc', 'Author', 'Body', 'Submission', 'Parent_ID', 'Parent_Author', 'Level']\n",
    "    writer = csv.DictWriter(file, fieldnames = headers, extrasaction='ignore')\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for psaw_submission in ids: #goes through list of ids matching criteria\n",
    "        post = reddit.submission(id = psaw_submission.d_['id']) #turns psaw submission into praw submission\n",
    "        post.comments.replace_more(limit = 0)\n",
    "        \n",
    "        for comment in post.comments: #goes through top level comments \n",
    "            if (not post.author) and (not comment.author): #skip if both post and comment author deleted\n",
    "                continue\n",
    "            data = {'ID':comment.id, 'Date_utc':comment.created_utc, 'Author':comment.author, 'Body': comment.body,\n",
    "            'Submission':post.id, 'Parent_ID':post.id, 'Parent_Author':post.author, 'Level':1}\n",
    "            writer.writerow(data)\n",
    "            \n",
    "            for reply in comment.replies: #second level comments\n",
    "                if not reply.author: #account deleted/comment deleted/moderator removed\n",
    "                    continue\n",
    "                data = {'ID':reply.id, 'Date_utc':reply.created_utc, 'Author':reply.author, 'Body': reply.body,\n",
    "                        'Submission':post.id, 'Parent_ID':comment.id, 'Parent_Author':comment.author, 'Level':2}\n",
    "                writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a4684e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"C:\\\\Users\\\\chris\\\\Documents\\\\Math168Project\\\\conspiracy_subs.csv\", 'a', encoding=\"utf-8\") as file:\n",
    "#     #setting up the csv file\n",
    "#     headers = ['ID', 'Date_utc', 'Author', 'Body', 'Parent_ID', 'Parent_Author', 'Post_ID', 'Post_Title', 'Subreddit_ID']\n",
    "#     writer = csv.DictWriter(file, fieldnames = headers, extrasaction='ignore')\n",
    "#     writer.writeheader()\n",
    "    \n",
    "#     for psaw_submission in ids: #goes through list of ids matching criteria\n",
    "#         post = reddit.submission(id = psaw_submission.d_['id']) #turns psaw submission into praw submission\n",
    "       \n",
    "#         post.comments.replace_more(limit = 0)\n",
    "#         for comment in post.comments.list(): \n",
    "#             if not comment.author: #skip if comment author deleted\n",
    "#                 continue\n",
    "#             if comment.author == 'AutoModerator': #skip automatic comments\n",
    "#                 continue\n",
    "#             parent_author = reddit.comment(id = comment.parent_id).author\n",
    "#             data = {'ID':comment.id, 'Date_utc':comment.created_utc, 'Author':comment.author, 'Body': comment.body,\n",
    "#                     'Parent_ID':comment.parent_id, 'Parent_Author':parent_author, \n",
    "#                     'Post_ID':post.id, 'Post_Title': post.title,\n",
    "#                    'Subreddit_ID':comment.subreddit_id}\n",
    "#             writer.writerow(data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb352f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
